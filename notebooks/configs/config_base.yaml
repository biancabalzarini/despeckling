# Parámetros del entrenamiento
training:
  n: 50000                # Cantidad de imágenes a generar para entrenar
  n_cuad_lado: [2]          # Cantidad de cuadrados por lado que van a tener las imágenes (cada cuadrado con diferentes parámetros de la GI0)
  pixeles_cuad: [25]        # Cantidad de píxeles por lado que tiene cada cuadrado de las imágenes
  num_epochs: 5           # Cantidad de épocas
  batch_size: 64          # Cantidad de imágenes en cada batch
  learning_rate: 0.001    # Learning rate
  scheduler_name: None    # Opciones: "rlrop", "slr", "elr"
                          # Scheduler para learning rate adaptativo
  scheduler_params: None  # Dict con los parámetros del scheduler
                          # Si es rlop, los params son: mode, factor y patience
                          # Si es slr, los params son: step_size y gamma
                          # Si es elr, los params son: gamma

# Parámetros generales del modelo
model:
  encoding_dim: 32      # Dimensión del espacio latente
  loss_function: "mse"  # Opciones: "mse", "bce"
                        # Binary Cross Entropy Loss como loss function puede ser una buena idea ya que las imágenes están normalizadas en el rango [0, 1]
  optimizer: "adam"     # Opciones: "adam", "sgd"
                        # El optimizador es responsable de ajustar los pesos del modelo con el fin de minimizar la función de pérdida.
                        # Adam es un algoritmo de optimización popular y eficiente que adapta la tasa de aprendizaje de forma dinámica para cada parámetro del modelo.
                        # La tasa de aprendizaje determina qué tan rápido se ajustan los pesos del modelo durante el entrenamiento.

# Arquitectura del encoder
encoder:
  layers:
    - type: "conv2d"
      filters: 16
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "relu"
    - type: "maxpool2d"
      pool_size: 2
    - type: "flatten"
    - type: "dense"
      dim: 128
      activation: "relu"
    - type: "dense"
      dim: "${model.encoding_dim}"

# Arquitectura del decoder
decoder:
  layers:
    - type: "dense"
      dim: 128
      activation: "relu"
    - type: "dense"
      dim: "${eval:'(${training.n_cuad_lado[0]} * ${training.pixeles_cuad[0]})**2'}"
      activation: "relu"
    - type: "unflatten"
      dim1: "${eval:'${training.n_cuad_lado[0]} * ${training.pixeles_cuad[0]}'}"
      dim2: "${eval:'${training.n_cuad_lado[0]} * ${training.pixeles_cuad[0]}'}"
    - type: "conv2d_transpose"
      filters: 16
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "relu"
    - type: "conv2d_transpose"
      filters: 1
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "sigmoid"

# Parámetros de la evaluación
testing:
  n: 1000         # Cantidad de imágenes a generar para evaluar
  batch_size: 32  # Cantidad de imágenes en cada batch