# Par치metros del entrenamiento
training:
  n: 100000
  n_cuad_lado: [1,2,3]
  pixeles_cuad: [60,30,20]
  ratio: [0.3,0.4,0.3]
  num_epochs: 100
  batch_size: 64
  learning_rate: 0.001
  scheduler_name: "rlrop"
  scheduler_params: {
      factor: 0.8
    }

# Par치metros generales del modelo
model:
  encoding_dim: 64
  loss_function: "mse"
  optimizer: "adam"

# Arquitectura del encoder
encoder:
  layers:
    - type: "conv2d"
      filters: 32
      kernel_size: 3
      stride: 2
      padding: 3
      activation: "relu"
    - type: "conv2d"
      filters: 64
      kernel_size: 3
      stride: 2
      padding: 1
      activation: "relu"
    - type: "flatten"
    - type: "dense"
      dim: "${model.encoding_dim}"
      activation: "relu"

# Arquitectura del decoder
decoder:
  layers:
    - type: "dense"
      dim: 16384
      activation: "relu"
    - type: "unflatten"
      dim1: 16
      dim2: 16
      out_channels: 64
    - type: "conv2d_transpose"
      filters: 32
      kernel_size: 2
      stride: 2
      padding: 0
      activation: "relu"
    - type: "conv2d_transpose"
      filters: 1
      kernel_size: 2
      stride: 2
      padding: 2
      activation: "sigmoid"

# Par치metros de la evaluaci칩n
testing:
  n: 10000
  batch_size: 32