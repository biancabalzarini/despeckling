# Par치metros del entrenamiento
training:
  num_epochs: 300
  batch_size: 64
  learning_rate: 0.001
  scheduler_name: "elr"
  scheduler_params: {
      gamma: 0.97
    }
  side_size: 256

# Par치metros generales del modelo
model:
  encoding_dim: 1500
  loss_function: "mse"
  optimizer: "adam"

encoder:
  layers:
    # Bloque 1 (128x128 -> 64x64)
    - type: "conv2d"
      filters: 32
      kernel_size: 10
      stride: 2
      padding: 4
      activation: "relu"
    
    # Bloque 2 (64x64 -> 32x32)
    - type: "conv2d"
      filters: 64
      kernel_size: 8
      stride: 2
      padding: 3
      activation: "relu"
    
    # Bloque 3 (32x32 -> 16x16)
    - type: "conv2d"
      filters: 128
      kernel_size: 6
      stride: 2
      padding: 2
      activation: "relu"
    
    # Bloque 4 (16x16 -> 8x8) - Cuello de botella
    - type: "conv2d"
      filters: 256
      kernel_size: 4
      stride: 2
      padding: 1
      activation: "relu"

decoder:
  layers:
    # Bloque 1 (8x8 -> 16x16)
    - type: "conv2d_transpose"
      in_channels: 256  # Debe coincidir con los 256 del encoder
      filters: 128
      kernel_size: 4
      stride: 2
      padding: 1
      output_padding: 0
      activation: "relu"
    
    # Bloque 2 (16x16 -> 32x32)
    - type: "conv2d_transpose"
      in_channels: 128
      filters: 64
      kernel_size: 6
      stride: 2
      padding: 2
      output_padding: 0
      activation: "relu"
    
    # Bloque 3 (32x32 -> 64x64)
    - type: "conv2d_transpose"
      in_channels: 64
      filters: 32
      kernel_size: 8
      stride: 2
      padding: 3
      output_padding: 0
      activation: "relu"
    
    # Bloque 4 (64x64 -> 128x128)
    - type: "conv2d_transpose"
      in_channels: 32
      filters: 1
      kernel_size: 10
      stride: 2
      padding: 4
      output_padding: 0
      activation: "sigmoid"
      
# Par치metros de la evaluaci칩n
testing:
  batch_size: 32