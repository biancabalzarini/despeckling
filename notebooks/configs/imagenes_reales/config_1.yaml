# Parámetros del entrenamiento
training:
  num_epochs: 100        # Cantidad de épocas
  batch_size: 64         # Cantidad de imágenes en cada batch
  learning_rate: 0.001   # Learning rate
  scheduler_name: "elr"  # Opciones: "rlrop", "slr", "elr"
                         # Scheduler para learning rate adaptativo
  scheduler_params: {    # Dict con los parámetros del scheduler
      gamma: 0.95        # Si es rlop, los params son: mode, factor y patience
    }                    # Si es slr, los params son: step_size y gamma
                         # Si es elr, los params son: gamma

# Parámetros generales del modelo
model:
  encoding_dim: 3200    # Dimensión del espacio latente
  loss_function: "mse"  # Opciones: "mse", "bce"
                        # Binary Cross Entropy Loss como loss function puede ser una buena idea ya que las imágenes están normalizadas en el rango [0, 1]
  optimizer: "adam"     # Opciones: "adam", "sgd"
                        # El optimizador es responsable de ajustar los pesos del modelo con el fin de minimizar la función de pérdida.
                        # Adam es un algoritmo de optimización popular y eficiente que adapta la tasa de aprendizaje de forma dinámica para cada parámetro del modelo.
                        # La tasa de aprendizaje determina qué tan rápido se ajustan los pesos del modelo durante el entrenamiento.

encoder:
  layers:
    - type: "conv2d"
      filters: 16
      kernel_size: 5
      stride: 2
      padding: 2
      activation: "relu"  # 512→256
    - type: "conv2d"
      filters: 32
      kernel_size: 5
      stride: 2
      padding: 2
      activation: "relu"  # 256→128
    - type: "conv2d"
      filters: 64
      kernel_size: 5
      stride: 2
      padding: 2
      activation: "relu"  # 128→64
    - type: "conv2d"
      filters: 128
      kernel_size: 5
      stride: 2
      padding: 2
      activation: "relu"  # 64→32
    - type: "flatten"
    - type: "dense"
      dim: "${model.encoding_dim}"
      activation: "relu"

decoder:
  layers:
    - type: "dense"
      dim: 131072  # 128*32*32
      activation: "relu"
    - type: "unflatten"
      dim1: 32
      dim2: 32
      out_channels: 128
    - type: "conv2d_transpose"
      filters: 64
      kernel_size: 4  # Cambiado de 5 a 4
      stride: 2
      padding: 1
      output_padding: 0
      activation: "relu"  # 32→64
    - type: "conv2d_transpose"
      filters: 32
      kernel_size: 4
      stride: 2
      padding: 1
      output_padding: 0
      activation: "relu"  # 64→128
    - type: "conv2d_transpose"
      filters: 16
      kernel_size: 4
      stride: 2
      padding: 1
      output_padding: 0
      activation: "relu"  # 128→256
    - type: "conv2d_transpose"
      filters: 1
      kernel_size: 4
      stride: 2
      padding: 1
      output_padding: 0
      activation: "sigmoid"  # 256→512

# Parámetros de la evaluación
testing:
  batch_size: 32  # Cantidad de imágenes en cada batch