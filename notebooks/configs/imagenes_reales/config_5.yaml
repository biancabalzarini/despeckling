# Parámetros del entrenamiento
training:
  num_epochs: 200
  batch_size: 64
  learning_rate: 0.001
  scheduler_name: "elr"
  scheduler_params: {
      gamma: 0.9999
    }
  side_size: 256

# Parámetros generales del modelo
model:
  encoding_dim: 1500
  loss_function: "mse"
  optimizer: "adam"

encoder:
  layers:
    # Bloque 1
    - type: "conv2d"
      filters: 8
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "leaky_relu"

    - type: "conv2d"
      filters: 16
      kernel_size: 4
      stride: 2
      padding: 1
      activation: "relu"
    
    - type: "maxpool2d"
      pool_size: 2
      stride: 2

    # Bloque 2
    - type: "conv2d"
      filters: 32
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "leaky_relu"
    
    - type: "maxpool2d"
      pool_size: 2
      stride: 2

    # Bloque 3
    - type: "conv2d"
      filters: 64
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "leaky_relu"

decoder:
  layers:
    # Bloque 1 - Asegurar que los canales coincidan
    - type: "conv2d_transpose"
      in_channels: 64  # ¡Nuevo parámetro requerido!
      filters: 32       # Reduce canales
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "leaky_relu"
    
    - type: "upsample"
      scale_factor: 2
      mode: "bilinear"

    # Bloque 2
    - type: "conv2d_transpose"
      in_channels: 32   # Coincide con salida anterior
      filters: 16
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "leaky_relu"
    
    - type: "upsample"
      scale_factor: 2
      mode: "bilinear"
    
    - type: "conv2d_transpose"
      filters: 8
      kernel_size: 4
      stride: 2
      padding: 1
      in_channels: 16
      activation: "relu"

    # Capa final
    - type: "conv2d"
      in_channels: 8    # Coincide con salida anterior
      filters: 1
      kernel_size: 3
      stride: 1
      padding: 1
      activation: "sigmoid"
      
# Parámetros de la evaluación
testing:
  batch_size: 32