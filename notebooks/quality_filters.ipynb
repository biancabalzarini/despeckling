{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scripts.GenrationGI0 import generate_multiple_images, mixed_dataset\n",
    "from scripts.autoencoders import InMemoryImageDataset, ConfigurableAutoencoder\n",
    "from scripts.measuring_quality import selecting_quadrants, quadrants_to_pixels, selecting_homogeneous_areas\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    OmegaConf.register_new_resolver(\"eval\", eval)\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegir el archivo de configuración correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': {'n': 100000, 'n_cuad_lado': [1, 2], 'pixeles_cuad': [50, 25], 'ratio': [0.45, 0.55], 'num_epochs': 500, 'batch_size': 64, 'learning_rate': 0.001, 'scheduler_name': 'elr', 'scheduler_params': {'gamma': 0.95}}, 'model': {'encoding_dim': 32, 'loss_function': 'mse', 'optimizer': 'adam'}, 'encoder': {'layers': [{'type': 'conv2d', 'filters': 16, 'kernel_size': 3, 'stride': 2, 'padding': 1, 'activation': 'relu'}, {'type': 'flatten'}, {'type': 'dense', 'dim': '${model.encoding_dim}', 'activation': 'relu'}]}, 'decoder': {'layers': [{'type': 'dense', 'dim': 10000, 'activation': 'relu'}, {'type': 'unflatten', 'dim1': 25, 'dim2': 25, 'out_channels': 16}, {'type': 'conv2d_transpose', 'filters': 1, 'kernel_size': 2, 'stride': 2, 'padding': 0, 'activation': 'sigmoid'}]}, 'testing': {'n': 1000, 'batch_size': 32}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_name = 'config_base_simetrico_mix_imagenes' # Elegir\n",
    "\n",
    "config_path = f'configs/{config_name}.yaml'\n",
    "config = OmegaConf.load(config_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if min(config.training.pixeles_cuad) < 8:\n",
    "    warnings.warn(\n",
    "        \"¡El método de primer orden va a fallar!\\n\"\n",
    "        \"Existen imágenes con cuadrantes demasiado pequeños, \"\n",
    "        \"y este método necesita zonas homogéneas más grandes.\",\n",
    "        category=UserWarning\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el autoencoder ya entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfigurableAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=10000, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=10000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Unflatten(dim=1, unflattened_size=(16, 25, 25))\n",
       "    (3): ConvTranspose2d(16, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Crear una instancia del modelo (debe tener la misma arquitectura)\n",
    "autoencoder_cargado = ConfigurableAutoencoder(config=config)\n",
    "# 2. Carga los parámetros\n",
    "autoencoder_cargado.load_state_dict(torch.load(f'data/trained_models/{config_name}.pth'))\n",
    "# 3. Modo evaluación (cuando lo use para inferencia)\n",
    "autoencoder_cargado.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero dataset de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = config['testing']['n']\n",
    "batch_size = config['testing']['batch_size']\n",
    "n_cuad_lado = config['training']['n_cuad_lado']\n",
    "pixeles_cuad = config['training']['pixeles_cuad']\n",
    "\n",
    "test_g, test_gi, test_gI0, alphas = mixed_dataset(\n",
    "    n_total = n,\n",
    "    generate_multiple_images = generate_multiple_images,\n",
    "    conjunto_n_cuad_lado = n_cuad_lado,\n",
    "    conjunto_pixeles_cuad = pixeles_cuad,\n",
    "    ratios = config.training.get('ratio',[1]),\n",
    "    save_alpha_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_to_01 = transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_to_01\n",
    "])\n",
    "\n",
    "dataset_test = InMemoryImageDataset(test_gI0, test_gi, transform=transform)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero las imágenes procesadas por el autoencoder, y genero las imágenes de ratio (imagen original / imagen filtrada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "all_targets = []\n",
    "all_outputs = []\n",
    "all_ratios = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for entrada, salida in test_loader:\n",
    "        entrada = entrada.float()\n",
    "        salida = salida.float()\n",
    "        outputs = autoencoder_cargado(entrada)\n",
    "        ratios = entrada / outputs\n",
    "        \n",
    "        all_inputs.append(entrada.cpu().numpy())\n",
    "        all_targets.append(salida.cpu().numpy())\n",
    "        all_outputs.append(outputs.cpu().numpy())\n",
    "        all_ratios.append(ratios.cpu().numpy())\n",
    "\n",
    "inputs = np.squeeze(np.concatenate(all_inputs, axis=0))\n",
    "targets = np.squeeze(np.concatenate(all_targets, axis=0))\n",
    "outputs = np.squeeze(np.concatenate(all_outputs, axis=0))\n",
    "ratios = np.squeeze(np.concatenate(all_ratios, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico un set de imágenes a modo de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ecualizar_hist = True  # Si se quiere o no ecualizar el histograma de la imagen\n",
    "\n",
    "###\n",
    "\n",
    "def graph_random_image_with_ratios(inputs, targets, outputs, ratios, ecualizar_hist, show_plot=True):\n",
    "\n",
    "    index = int(n*np.random.random()) # Índice del ejemplo puntual que se desea seleccionar\n",
    "    entrada_red, target_red, salida_red, ratios = inputs[index, :, :], targets[index, :, :], outputs[index, :, :], ratios[index, :, :]\n",
    "\n",
    "    imagenes = [entrada_red, target_red, salida_red, ratios]\n",
    "    titulos = ['Entrada', 'Salida esperada', 'Salida de la red', 'Ratio original/filtrada']\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    for ax, imagen, titulo in zip(axes, imagenes, titulos):\n",
    "        if ecualizar_hist:\n",
    "            imagen = ((imagen - imagen.min()) * 255) / (imagen.max() - imagen.min())\n",
    "            imagen = cv2.equalizeHist(imagen.astype(np.uint8))\n",
    "            titulo += '\\n(ecualizada)'\n",
    "        \n",
    "        ax.imshow(imagen, cmap='gray')\n",
    "        ax.set_title(titulo)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "graph_random_image_with_ratios(inputs, targets, outputs, ratios, ecualizar_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BORRAR\n",
    "# AHORA TENGO QUE ELEGIR n (5 o 4) AREAS QUE ENTREN EN LA IMAGEN, Y QUE SEAN HOMOGENEAS (QUE NO SE CRUCEN DE CUADRANTE\n",
    "# Y QUE TENGAN ALPHA MENOR O IGUAL A -6). LAS ZONAS DE AREA 10X10 O 8X8. YO TOMARIA DE 10X10, SI NO ENTRA EN UN\n",
    "# CUADRANTE, DE 9X9. Y SI NO ENTRA, DE 8X8. y SI NO ENTRA, QUE FALLE Y DECIR QUE LA IMAGEN ES MUY POCO HOMOGENEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuadrantes = selecting_quadrants(alphas, M=5)\n",
    "cuadrantes_i, cuadrantes_f = quadrants_to_pixels(cuadrantes, config.training.pixeles_cuad, alphas)\n",
    "del cuadrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min(config.training.pixeles_cuad) >= 8, \"Existen imágenes muy poco homogéneas en su dataset. Para poder \\\n",
    "usar el filtro de primer orden se necesita que los cuadrantes de todas las imágenes sean de al menos 8x8 píxeles.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 13, 15, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zona_xi, zona_yi, zona_xf, zona_yf = selecting_homogeneous_areas(cuadrantes_i[998][2], cuadrantes_f[998][2])\n",
    "zona_xi, zona_yi, zona_xf, zona_yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zona = imagen[zona_xi:zona_xf, zona_yi:zona_yf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cuadrantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 0), (0, 1), (1, 0), (1, 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadrantes[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
