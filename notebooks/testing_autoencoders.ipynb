{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jugando con autoenconders\n",
    "Esta notebook tiene el único objetivo de hacer primeras pruebas con autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura del autoencoder\n",
    "class Autoencoder(nn.Module): # La clase Autoencoder hereda de la clase nn.Module, que es una clase base para todos los modelos en PyTorch.\n",
    "                              # Esto permite que nuestra clase Autoencoder tenga todas las funcionalidades necesarias para ser un modelo de aprendizaje profundo en PyTorch.\n",
    "\n",
    "    # Dentro del método __init__, definimos las capas del autoencoder.\n",
    "    def __init__(self, encoding_dim):\n",
    "\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential( # Encoder\n",
    "                                      # Toma una imagen de entrada y la comprime en una representación de dimensionalidad más baja llamada encoding_dim\n",
    "\n",
    "            # Secuencia de capas del codificador:\n",
    "            nn.Linear(28 * 28, 128), # Capa lineal inicial que toma una imagen de 28x28 píxeles (784 dimensiones después de aplanarla) y la reduce a 128 dimensiones utilizando una función lineal.\n",
    "            nn.ReLU(), # Luego se aplica una función de activación ReLU para introducir no linealidad en la representación.\n",
    "            nn.Linear(128, encoding_dim), # Finalmente, otra capa lineal reduce la dimensionalidad a encoding_dim.\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential( # Decoder\n",
    "                                      # Devuelve la imágen a su tamaño original.\n",
    "\n",
    "            # Secuencia de capas del decodificador:\n",
    "            nn.Linear(encoding_dim, 128), # Capa lineal que toma la representación de encoding_dim y la expande a 128 dimensiones.\n",
    "            nn.ReLU(), # Luego, se aplica una función de activación ReLU.\n",
    "            nn.Linear(128, 28 * 28), # A continuación, otra capa lineal expande la dimensionalidad a 28x28 píxeles (784 dimensiones).\n",
    "            nn.Sigmoid(), # Finalmente se aplica una función de activación sigmoide para limitar los valores de salida entre 0 y 1.\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # El método forward define cómo se propagan los datos a través del autoencoder.\n",
    "\n",
    "        encoded = self.encoder(x) # Toma una imagen de entrada x, la pasa por el codificador para obtener la representación comprimida encoded.\n",
    "        decoded = self.decoder(encoded) # Luego pasa esta representación por el decodificador para obtener la reconstrucción decoded.\n",
    "        return decoded # La reconstrucción se devuelve como salida.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "despeckling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
